### Функции потерь и базовые подходы к обучению моделей ранжирования  
В этом домашнем задании необходимо реализовать обучение ListNet на подвыборке датасета MSRANK_10K. В первую очередь необходимо согласно разобранному на практике материалу определить структуру ListNet (в self.model). В рамках выполнения задания попробуйте разные конфигурации слоёв (Dropout, нелинейности) и разное количество нейронов. Однако имейте в виду, что даже с простой архитектурой из практической части вполне реально обучить модель, проходящую проверку.

#### Класс Solution
Весь остальной код должен быть представлен в классе Solution. Параметры класса при инициализации:

n_epochs — количество эпох или проходов по тренировочному датасету (сколько раз нейросеть увидит каждый объект).

listnet_hidden_dim — размерность скрытого слоя ListNet.

lr — Learning Rate при обучении модели (коэффициент, на который умножаются градиенты ошибки при обучении во время градиентного спуска).

ndcg_top_k — количество объектов, на которых рассчитывается NDCG при валидации.

Метод _get_data уже реализован — ознакомьтесь с кодом и более внимательно рассмотрите датасет MSRANK_10K, данные которого будут храниться в датафреймах. Если вам интересно, описание всех признаков можно найти на официальном сайте по ссылке. Именно на основе этих фичей и будет производиться оценка релевантности. Помимо признаков (X_train, X_test) и меток релевантности (y_train, y_test) также используются уникальные идентификаторы запросов (query_ids_train, query_ids_test). Именно в рамках группировки по этим идентификаторам и будет рассчитываться метрика NDCG. 

Метод _prepare_data нужно дописать: необходимо отнормировать признаки X_train и X_test в рамках каждого отдельного идентификатора запроса. Для этого нужно имплементировать метод _scale_features_in_query_groups, после чего вызвать его в рамках _prepare_data. Для нормализации необходимо использовать StandardScaler из библиотеки sklearn. После применения каждый признак в рамках группы будет иметь среднее нуль и стандартное отклонение 1. Это необходимо для корректного обучения нейронной сети. 

Не лик ли это? Как можно нормировать данные в валидации?
Нет, это не лик, так как происходит нормировка в рамках каждой группы для каждого запроса. Как говорилось на одной из лекций, модели ранжирования лишь реранжируют уже некоторый подготовленный топ, и потому к моменту применения нейросети вектора признаков уже известны. Таким образом, модель, наоборот, получается более робастной, имея возможность сравнивать выровненные распределения в рамках каждого запроса. Главное, что сохраняется относительная информация (порядок), так как стандартизация — монотонное преобразование. Такой трюк часто применяется в моделях ранжирования и матчинга.

Затем нужно поместить все переменные с признаками и таргетами в тензоры (torch.FloatTensor) для удобства их дальнейшего использования во время обучения и валидации. Их размерности должны быть N∗D и N для признаков и лейблов соответственно, где N — количество объектов в выборке, а D — количество признаков. Целевые метки нужно разместить в атрибутах с названиями ys_train и ys_test соответственно для тренировочной и тестовой выборок. 

В методе _create_model необходимо инициализировать (создать модель) реализованный вами ListNet согласно параметрам из init-метода класса Solution.

#### Приступаем к реализации методов обучения и валидации модели
Для начала нужно реализовать вычисление NDCG@k в методе _ndcg_k. Здесь разрешается переиспользовать код из домашнего задания к прошлой лекции. Важно внести изменения, чтобы расчёт шел только в топ-K позиций (включая IdealDCG).

В этой домашней работе и далее предполагается использование экспоненциальной версии вычисления NDCG, проверьте параметры функции во избежание недоразумений. 

Метод _calc_loss принимает на вход целевые метки и предсказания и возвращает значение функции потерь. Можете использовать любую ListNet-like функцию потерь из разобранных на лекции (даже KL-дивергенцию).

В рамках _train_one_epoch необходимо организовать разовый проход по всем группам из тренировочного датасета. Таким образом, на каждом шаге обучения ListNet подаются лишь те объекты выборки, которые относятся к одному id (ведь функция ошибки считается по набору документов, относящихся обязательно к одному запросу). Используйте для вычисления ошибки и оптимизации метод _calc_loss.

Для контроля хода обучения пригодится метод _eval_test_set — он также проходит по группам объектов, получает предсказания модели, после чего рассчитывает NDCG@K и возвращает усреднённое по всем id значение. Если NDCG рассчитать невозможно или по каким-то причинам появляется ошибка, то NDCG=0 (а не пропускается). 

И жемчужина класса Solution — метод fit, вызывающий обучение и валидацию модели в течение N эпох. Метод возвращает валидационные значения NDCG после каждой эпохи. Необходимо, чтобы ваша модель получала значение NDCG@10 не ниже 0.41 после тренировки в течение 5 эпох при lr=0.001. На тренировку отведено не более 60 секунд. 
